<h1 align="center">Проект по распознованию сгенерированного AI моделью текста</h1>

Проект по распознованию AI-сгенерированного текста, основные компоненты:

    * CPU сервер с FastAPI сервером, на котором будет происходить взаимодействие с пользователем.
    
    * GPU сервер с AI моделью, которая проводит скоринг по запросу с CPU сервера.


<h1 align="center">GPU часть проекта</h1>

Запускается на втором сервере архитектуры - GPU. Сервис ожидает сообщение пользователя от CPU сервера.

Клиент отправляет запрос на CPU сервер (бекенд веб приложения), CPU сервер отправляет запрос на обработку текста в GPU сервер через брокера сообщений rabbitmq и записывает лог в БД. GPU получает запрос на обработку через rabbitmq, результат кладет в БД обновляя лог оставленный CPU сервисом.


<h1 align="center">Настройка сервисов на GPU</h1>

Выполняется после развертывания необходимого ПО на сервере (~/README.MD, пункт 1-3)


<h3 align="center">1. Поднимаем сервисы </h3>

<b>1.1 Редактируем ~/gpu_server/main.py - указываем IP адрес CPU сервера (12 строка)</b>

<code>CPU_SERVER_IP = '178.253.40.134'</code> 


<h3 align="center">2. Поднимаем сервисы </h3>

<b>2.1 Создаем docker образ (Только из Dockerfile)</b>

<code>docker build -t gpu .</code> 

<b>2.2 Запускаем сервис  </b>

<code>docker run gpu </code> 


<h3 align="center">3. Запрос к сервису (образаемся к CPU) </h3>

Выполняется после настройки CPU сервиса (~/cpu_server/README.MD пункты 1-3)

<b>Отправляем запрос на сервис. Ожидается ответ.</b>

Ожидается ответ в виде числа, которое может быть оценкой вероятности того, что текст был сгенерирован моделью

<code>curl -X POST "http://92.255.111.116:8000/predict" -H "Content-Type: application/json" -d '{"text": "Привет как дела?"}' </code> 

Ответ: {"text":"Привет как дела?","result":"Processed text: Привет как дела?, **probability generated text = 0.013**"}% 


<h1 align="center">Файлы из директории GPU сервера</h1>

**main.py** - скрипт для запуска сервиса на GPU сервере. В дальнейшем тут будет работать AI модель по распознованию
сгенерированного текста другой AI моделью, на данный момент тут стоит заглушка np.random.rand()

**Dockerfile** Инструкция для развертывания сервиса с "моделью"

**pyproject.toml** Poetry инструкция для настройки виртуального окружения