from fastapi import FastAPI
from pydantic import BaseModel
from dotenv import load_dotenv

import os
import aio_pika
import asyncio
import json
import uuid
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

load_dotenv()

RABBITMQ_DEFAULT_USER = os.getenv("RABBITMQ_DEFAULT_USER")
RABBITMQ_DEFAULT_PASS = os.getenv("RABBITMQ_DEFAULT_PASS")

if not RABBITMQ_DEFAULT_USER or not RABBITMQ_DEFAULT_PASS:
    raise ValueError("RABBITMQ_DEFAULT_USER and RABBITMQ_DEFAULT_PASS must be set in the .env file")


app = FastAPI()

class TextInput(BaseModel):
    '''Model for input data'''
    text: str

async def connect_to_rabbitmq():
    '''Get connect to RabbitMQ from rabbitmq container'''
    return await aio_pika.connect_robust(
        f"amqp://{RABBITMQ_DEFAULT_USER}:{RABBITMQ_DEFAULT_PASS}@rabbitmq/"
    )

async def get_response(callback_queue, correlation_id):
    '''Listen request GPU-server from queue RabbitMQ'''
    try:
        message = await asyncio.wait_for(
            callback_queue.get(), 
            timeout=60.0
        )
        async with message.process():
            logger.info(f"Received message: {message.body.decode()}")
            if message.correlation_id == correlation_id:
                return message.body.decode()
            else:
                logger.error(f"Mismatched ID: Expected {correlation_id}, Got {message.correlation_id}")
                return "Invalid correlation ID"
    except asyncio.TimeoutError:
        logger.error("Timeout waiting for response")
        return "Timeout"
    except Exception as e:
        logger.error(f"Error: {str(e)}")
        return f"Error: {str(e)}"


@app.get("/")
def read_root():
    return {"message": "Probability prediction is the text generated by the model!"}

# The route for processing the POST request
@app.post("/predict")
async def predict(text_input: TextInput):
    '''Post request processing'''
    try:
        connection = await connect_to_rabbitmq()
        channel = await connection.channel()
        correlation_id = str(uuid.uuid4())
        message = {"text": text_input.text}

        # We are announcing the exchanger
        exchange = await channel.declare_exchange(
            "direct_exchange", 
            aio_pika.ExchangeType.DIRECT, 
            durable=True
        )

        # Declaring and linking a queue for results
        result_queue = await channel.declare_queue("results_pred_gen_txt", durable=True)
        await result_queue.bind(exchange="direct_exchange", routing_key="results_pred_gen_txt")

        # publish message
        await exchange.publish(
            aio_pika.Message(
                body=json.dumps(message).encode(),
                correlation_id=correlation_id,
                reply_to="results_pred_gen_txt" # where should the gpu service's response be sent
            ),
            routing_key="tasks_pred_gen_txt",
        )

        logger.info(f"Send message with correlation_id: {correlation_id}")

        await asyncio.sleep(1)
        
        # Get a response
        response = await get_response(result_queue, correlation_id)
        logger.info(f"Post from server GPU! Sent result: {response}")

        return {"text": text_input.text, "result": response}

    except Exception as e:
        logger.error(f"Error in predict: {e}")
        return {"error": str(e)}
    finally:
        if connection:
            await connection.close()


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)